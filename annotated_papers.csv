title,abstract,category
Beyond Value-Function Gaps: Improved,Instance-Dependent Regret Bounds for Episodic Reinforcement Learning Chris Dann Google Research,Reinforcement Learning
We appreciate the reviewer’s constructive suggestions. Reviewer 1 and 2 highly evaluate our work. It looks the score,"1 of Reviewer 3 and 4 is mostly due to our paper’s presentation style. We will sincerely take their suggestion into 2 account in a revision phase. For each question, we answer as follows.",Computer Vision
From Canonical Correlation Analysis to,"Self-supervised Graph Neural Networks Hengrui Zhang1⇤, Qitian Wu2, Junchi Yan2, David Wipf3, Philip S. Yu1† 1 Department of Computer Science, University of Illinois at Chicago 2 Department of Computer Science and Engineering, Shanghai Jiao Tong University",Deep Learning
Multimodal Few-Shot Learning with,Frozen Language Models Maria Tsimpoukelli∗ DeepMind mrts@deepmind.com,Natural Language Processing
"First of all, we would like to thank all reviewers for the insightful comments and suggestions! Reviewers have also","1 raised many inspiring questions on asymmetric valleys (AVs), most of which we have addressed in this rebuttal. But for 2 some of them (like what network structure or loss function tend to cause AVs, and what other new theoretical results",Optimization
We would like to thank all referees for their appreciation of our results and the useful feedback. Below is our reply.,1 Reviewer 1: The regularized version of the FR problem is a geodesically convex optimization problem over the feasible 2 set Sn,Optimization
Time Discretization-Invariant,Safe Action Repetition for Policy Gradient Methods Seohong Park Seoul National University artberryx@snu.ac.kr,Reinforcement Learning
Predicting What You Already Know Helps:,"Provable Self-Supervised Learning Jason D. Lee1, Qi Lei1, Nikunj Saunshi1,",Deep Learning
Oracle Complexity in Nonsmooth Nonconvex,Optimization Guy Kornowski Weizmann Institute of Science guy.kornowski@weizmann.ac.il,Optimization
AUTHOR RESPONSE TO THE REVIEWS OF “CORMORANT: COVARIANT,MOLECULAR NEURAL NETWORKS” We thank all three reviewers for their insightful comments and positive evaluations of our manuscript. We will update the paper to reﬂect their suggestions by the camera ready deadline. We will shortly release a Python library that implements the Cormorant architecture. Currently we are,Deep Learning
We would like to thank all the reviewers for their thoughtful and generally positive comments. We address their concerns,"1 below, and will make corresponding clariﬁcations in the revision. 2 To Reviewer 1:",Computer Vision
"We thank the reviewers for their feedback, especially R1, R4 and R5 for appreciating the signiﬁcance of our work at","1 this juncture in deep learning theory. Below, we respond to the reviewers in order. 2 R1: Again, we thank the reviewer for their encouraging comments. As indicated in their suggested improvements, we",Deep Learning
"To all reviewers. We would like to sincerely thank you for your important ideas and constructive comments. First, we would like to","1 clarify that B-RAI [24] is a recently proposed algorithm for estimating the posterior probability of causal relations among observed 2 variables. It is not related to the deep learning domain. The B2N algorithm [25], introduces principles for converting ﬁxed causal",Deep Learning
We thank the reviewers for their thoughtful feedback. We are encouraged that all the reviewers found our work to,1 be creative in porting predictive coding and Bayesian brain theories in neuroscience to deep learning models using a 2 mathematically rigorous framework. We want to assure the reviewers that we will heed their advice such as making the,Deep Learning
We thank the reviewers for their feedback. We will reﬂect reviewer’s comments and our response in the revision.,"1 Reviewers showed concern on the novelty and the accuracy. FixMatch represents a signiﬁcant research advancement 2 because of its simplicity. While discovering new techniques and tricks is important, we believe that demonstrating",Computer Vision
Response to the Reviewers of “The Geometry of Deep Networks: Power Diagram Subdivision”,"1 We thank the reviewers for their careful reading, concrete suggestions, and interest in our manuscript. Responses to 2 your Detailed Comments are given below. If our paper is accepted, the Python/TensorFlow code for all the experiments",Computer Vision
"We thank reviewers for detailed comments and suggestions. We will address all comments in the revision. In this work,","1 we consider a novel unsupervised stochastic contextual bandits problem. In follow-on work, we will study relevant 2 open questions like, lower bounds, private information, and real-valued feedback, pointed out by reviewers.",Computer Vision
"We thank all of the reviewers for their time, effort and engagement with our work. Feedback is addressed below, and all",1 comments will be incorporated in the ﬁnal manuscript revision. 2 === General Comments ===,Computer Vision
We thank all reviewers for the constructive comments. We ﬁrst present new experimental results requested by the,"1 reviewers, and then address reviewers’ concern individually. All new results will be included in the revision. 2 R1 : We added a comparison to policy sketches (Andreas et al. ’17) on the Crafting environment from the same work.",Computer Vision
We are deeply appreciative of the reviewers for their feedback amidst these trying circumstances. We are glad that the,"1 reviewers appreciate the scalability challenge addressed by our work, and the neatness of our proposed algorithm. We 2 would like to emphasize that we compared with over 1056 benchmarks arising from the domain of neural network",Deep Learning
General Comment: We thank all the reviewers for providing comments that have been helpful for us to reassess the,1 strengths and weaknesses of the DeepGambler method and writing. The most important message of this paper is that 2 various connections between assessing prediction uncertainty in deep learning and ideas from portfolio theory can be,Deep Learning
"We thank the reviewers for their insightful comments, which we will incorporate into the revised version. We ﬁrst",1 address some common concerns raised by the reviewers by providing additional experiment results. 2 Design choices of graph neural networks (GNN),Deep Learning
"Figure 1: Left: Same setting as Figure 4, with 15 seeds. Mid and Right: Same setting as Figure 3 (left), with error","bars and result in low data regime. (Results with N = 1000, 5000 are similar and will be included in revision.) Larger set of b for baselines: BCQ: {0, 0.05, 0.1, 0.2}, SPIBB: {1e-4, 5e-4, 1e-3, 5e-3, 1e-2}, MBS: {5e-4, 1e-3, 5e-3} We thank the reviewers for the excellent feedback that helped us improve the manuscript. Our revision includes (1) 1",Computer Vision
We thank the Reviewers for their constructive comments that helped improve the paper. We address their comments and,"1 questions below, and modiﬁed the manuscript accordingly. 2 Reviewer 3 raised the question of the generalization to more complex agent morphologies, which was not addressed in",Reinforcement Learning
"We thank the reviewers for their extremely helpful feedback. We also thank all reviewers for pointing out the typos,","1 which we shall all correct in the ﬁnal revision. 2 Organization, Clarity, Notation: We appreciate your feedback regarding the organization. Due to space constraints,",Computer Vision
Response to all reviewers: We have signiﬁcantly updated the results of the paper to show that our meta-gradient,"1 method can indeed learn auxiliary questions fast enough to improve learning performance on the main task. In these 2 experiments, as suggested, we use both the actor-critic loss and the (continuously adapting) meta-learned auxiliary",Reinforcement Learning
"We would like to thank all the reviewers for thoughtful feedback. As the reviewers pointed out, SWAG is a very practical","1 Bayesian deep learning method readily applicable to ImageNet-scale problems. SWAG achieves strong results on image 2 classiﬁcation, tabular regression and language modeling, out-performing strong and elaborate Bayesian deep learning",Deep Learning
Reviewer 1.,"Q1: The paper does not address if this is of interest to broader vision/ml community. A1: Crowd 1 counting is a well established research problem in Computer Vision, with more than four dozen papers published at",Computer Vision
R1. Thank you for appreciating the theoretical contribution and signiﬁcance. Your main concern seems the performance,"1 difference in our soft actor-critic (SAC) compared to the SAC from [20,21] on HalfCheetah. This was earlier noted by 2 other researchers who tried to reproduce SAC results, leading to a GitHub issue which has been resolved just recently",Reinforcement Learning
"We thank all the reviewers for their efforts and constructive comments! Most reviewers (R1, R2 and R4) think our","1 method is novel, while having concerns on clarity and evaluation. Below we address the important and common issues. 2 1. Supervision and ablation study (R1, R2, R3). • Our method is self-supervised in the sense that it does not rely on",Computer Vision
We thank all the reviewers for the helpful comments. We will revise the paper to address your concerns.,"1 R1-Q1: The implementation seems straight-forward and the ablation analysis on the loss function. 2 In the beginning, based on the Up-Down model, we have attempted to implement the Constant Prophet Attention",Optimization
Table 1: DAVIS-2017 segmentation results.,"Model J (Mean) Self-supervised, SOTA [49] 43.0",Computer Vision
We thank the reviewers for their insightful comments. We summarize the questions from each reviewer below and,1 address them separately. We will incorporate the feedback and suggestions into the next revision of the paper. 2 (Reviewer 1) Q1: Clarify what information is exchanged between the agents.,Computer Vision
"We would like to thank the reviewers for their useful, detailed feedback! We will update the paper with the suggested","1 minor revisions regarding typos and presentation improvements, and respond to individual reviewers comments below. 2 Reviewer #1:",Computer Vision
Reviewer #2,1 – Generic NN formulation and relation to RNN: Our (14) is a highly structured neural network (NN) due to the 2 Mori-Zwanzig moment closure (please note the form of f in Eq.(7)). This enables us to learn the diffusion parameter,Deep Learning
We thank all reviewers for their thorough reviews and insightful feedback! We are encouraged that they found our work,"1 to be a novel [R1], but simple and effective [R4] way to combine two different lines of research on parallel sentence 2 mining and unsupervised machine translation [R1]. We also appreciate that all reviewers found our work well-motivated",Natural Language Processing
Author response: ‘Stationary Activations for Uncertainty Calibration in Deep Learning’,NeurIPS: #5154 1 We thank the anonymous reviewers for their enthusiasm and detailed comments on the manuscript. We summarise the 2,Deep Learning
We thank all the reviewers for such thoughtful and high-quality reviews as well as for the positive feedback! We will do,"1 our best to incorporate all the recommendations in the next revision of the paper. 2 R1, R3: Experiments on more datasets.",Computer Vision
We thank all the reviewers for their time and for raising several interesting questions. We also appreciate that the,"1 reviewers carefully read the paper, catching typos, and making useful suggestions. Please see our responses below. 2 Reviewer #1: The three minor issues raised by the reviewer will be addressed in the revision.",Computer Vision
We thank all reviewers for their time and great feedback. We’ll incorporate various suggestions and clariﬁcations in the,"1 revision. Here, we ﬁrst address the shared points, then individual comments. 2 Hyperparameters (R1 and R3).",Computer Vision
"AC and all Reviewers: We thank all reviewers. To summarize, all the reviewers acknowledged the novelty of our","1 transductive Mutual Information (MI) loss, the novelty of the ADM optimizer and the speed-up it brings, as well as the 2 SOTA results over 5 benchmarks, by signiﬁcant margins. The criticisms are essentially based on: discussions on recent",Optimization
We thank the reviewers for insightful comments and suggestions. We hope the rebuttal will clarify all the doubts.,"1 Motivation and real-world application In the LfL [1,2] setting, we do not ignore the near-optimal trajectories, 2 but we can use all the training data to recover the reward function. In some cases, such as in multi-agent IRL,",Reinforcement Learning
Reviewer 1,"Q: Novelty against [3]: The differences: (1) They do reinforcement learning, while we do imitation 1 learning, which is much harder. (2) We established a Bayesian formulation for MAIL to achieve sample efﬁciency. (3) 2",Reinforcement Learning
We thank the reviewers for the positive feedback and valuable comments. Our response follows.,"1 1) Computing smooth Wasserstein distance (SWD) [R3]: This is a great and important point. We will add a discus- 2 sion about computation to the revision. As R3 mentions, the placeholder MC algorithm we used, in theory, has an",Computer Vision
Author response for ‘When to use parametric models in reinforcement learning?’,"1 We sincerely appreciate the reviewers’ time and effort to provide useful and insightful reviews, and in this case of 2 course especially for their helpful comments and question about our paper.",Reinforcement Learning
We would like to thank all reviewers for their invaluable feedback. The next revision of the paper will include ﬁxes for,1 all typos that were mentioned. Responses for questions raised by each reviewer are below. 2 Reviewer #1,Computer Vision
We thank the reviewers for their valuable feedback. We will incorporate all clariﬁcations below in the ﬁnal version.,1 (R4) “Novelty is limited. It looks like the authors simply apply [Shu et al. 2020] to more challenging data.” The 2 key contribution of our work is using weak supervision to accelerate RL. Shu et al. does not consider the RL problem.,Computer Vision
[R1] Methods clariﬁcation. Sorry for not having made it clear enough. ShiftAddNet adopt SOTA bitwise-shift-based,1 and add-based networks’ design to do backpropagation (Line 176). We appreciate your suggestions and will include 2 detailed formulation/explanation for both the backpropagation and the “ﬁxing shift” extension in the ﬁnial revision.,Computer Vision
Network-to-Network Translation with,Conditional Invertible Neural Networks Author Response 1 We thank all the reviewers for their positive feedback and for valuing the importance of the problem and the novelty of,Deep Learning
Reviewer 1 and 4,"1 We thank for the reviews and will resolve the main concerns. We sincerely ask the reviewers to re-evaluate the rating. 2 - Reviewer 1: ""It is pointless to study the gradient descent method in this setting. Also, the proposed method, on the",Optimization
"Thank you all for the encouraging comments and helpful suggestions. Due to the space limit, we only respond to main","1 concerns, but will incorporate all comments in the ﬁnal revision. Citations in this rebuttal refer to those in the main paper. 2 Reviewer 1",Computer Vision
We thank the reviewers for their detailed comments. We are glad to see a generally positive assessment of our work. The,"1 main aim of our work is to develop reversible graph neural network models, called Graph Normalizing Flows (GNFs) 2 which can be used for both supervised learning and unsupervised learning. On supervised tasks, we show that the GNF",Deep Learning
"We thank the reviewers for their careful reading of the manuscript, and for their constructive comments. We feel that","1 the reviews are largely positive. In the remainder, we want to address some of the issues raised, and we will address 2 them in detail in the revision:",Computer Vision
We thank the reviewers for their insightful comments and suggestions. We respond to the major concerns below and,1 will incorporate all comments in the next revision. 2 Summary of contributions We presented a novel theoretical and empirical study of the gradient dynamics of overpa-,Computer Vision
We thank the reviewers for their insightful feedback. We address their concerns below.,"1 R1.Q1: Supervision Level. Existing single view reconstruction methods we compare to use synthetic renderings of 2 3D meshes for training. Therefore, camera poses and depth maps are available for free in this experimental setup.",Computer Vision
Re: Coupling-based Invertible Neural Networks Are Universal Diffeomorphism Approximators (ID=1064).,1 We thank the reviewers for reviewing our work. We will update the paper based on the suggestions. 2 To Reviewer #1,Deep Learning
"We thank the reviewers for the insightful comments, and we will update the paper accordingly.","1 R1Q1: compare with uncertainty learning methods. A: Using the loss from [“What Uncertainties Do We Need in 2 Bayesian Deep Learning for Computer Vision?”, NeurIPS 2017] on UCF-QNRF we obtain 103.2/168.2 (MAE/MSE),",Deep Learning
Reviewer #1:,Our key contribution is to explain mathematically how word embeddings of Glove/W2V capture 1 semantic properties of words. Whilst some aspects relate to previous empirical observations or hypotheses e.g. a 2,Natural Language Processing
"We thank the reviewers for their time and helpful suggestions, which we will use to improve the paper’s presentation.","1 R1, R2 (relevance of interpolation): Please refer to lines 39-42 for examples where interpolation is satisﬁed. Recent 2 work [5,7,42,46,77] views interpolation as key to understanding the effectiveness of SGD for deep learning. Moreover,",Deep Learning
We thank all the reviewers for their constructive feedback. Our revision will incorporate all the points detailed below.,"1 R#1: Theoretical advantage over comp-SCGD [8]. In the table below, we compare our bound to [8], which shows 2 that we have better dependency on κ (see our reply to reviewer #6 for how to derive the complexity in special cases).",Computer Vision
"(R1) Robustness analysis for supervised pre-training, self-supervised pre-training, and self-training. We agree","1 that robustness for pre-training and self-training is an interesting direction. However, unlike ImageNet, there is no 2 robustness benchmark for detection and segmentation. This can be very interesting future follow-up work.",Computer Vision
Revision summary: We thank all the reviewers for their insightful comments. We have added experiments on,"1 ResNet/DenseNet backbones, and optimized a more efﬁcient C2sp model for ImageNet: 2 0",Computer Vision
"We thank the reviewers for their thoughtful and constructive feedback, as well as the pointers to related work, which we",1 plan on incorporating in the next revision. 2 R1,Computer Vision
"We would like to thank the reviewers for their careful revision, positive comments and constructive criticism. We","1 address below some of the major criticism raised by reviewers. Due to space limitations, not all suggestions can be 2 included in the conference ﬁle, but we will make sure to include them in the full version of the paper.",Computer Vision
"Thanks for the very constructive feedback. Due to lack of space, we only address here the major issues that were raised.",1 We will however incorporate all feedback in our paper revision. 2 Power-law distribution of input referents (R1/R3).,Computer Vision
We thank the reviewers for their thoughtful comments and support. We want to emphasize that the paper provides many,"1 timely insights uniﬁed by a strong narrative around probabilistic model construction and generalization, showing the 2 role of multimodal marginalization, neural networks priors, tempering, support, and inductive biases — with signiﬁcant",Deep Learning
"In this paper, we propose to tackle the problem of multi-task reinforcement learning with a novel modular network","1 model. Instead of using hard selection on modules, we introduce a method called soft modularization which softly 2 combines the modules. Our approach enables efﬁcient optimization and sharing across modules. The role of each",Reinforcement Learning
We thank the reviewers for their detailed comments. Please see our response below.,1 R1: ◦“... common implementation of weight decay [1] will usually multiply the amount of weight decay by the learning 2 rate.” The same holds in our setup: We have an L2 regularization term in the loss. In the gradient descent update,Optimization
We gratefully thank all reviewers for their valuable comments. We will try our best to address them in the revision.,"1 Comments on Clarity for R #1. 2 (1) Thanks for pointing out the missing details in HINT paper, we will try to add a description of how the gradient-based",Computer Vision
"We thank the reviewers and are glad that they ﬁnd our work theoretically sound [R2, R3], well-written [R1, R2, R3, R4]","1 and empirically impressive [R1, R3]. R2 says “the paper is theoretically well grounded, and it is especially strong in 2 its integration of deep learning and control theory” and R4 ﬁnds it “important for combining high-frequency control",Deep Learning
"Figure 1: Projecting 50-dimensional embeddings obtained by training a simple neural network without SSE (Left), and","with SSE-Graph (Center) , SSE-SE (Right) into 3D space using PCA. Table 1: The experimental results of BERT-NER with SSE-SE and without SSE-SE when we only allow ﬁne-tuning BERT for one epoch and two epochs. The same set of hyper-parameters are used. One Epoch",Deep Learning
"We thank all reviewers for their valuable and positive feedback, and share their excitement that MDEQ validates implicit","1 models for large-scale vision applications. We address a few comments below, which we will incorporate into the paper. 2 Review #1.",Computer Vision
We thank the reviewers for their feedback. We are glad that they found the problem of combining classical planning,"1 with Reinforcement Learning important (R3), our experimental results and ablations to be compelling (R1,R5), and our 2 method to be sound (R1,R3). We are also pleased that the reviewers clearly identiﬁed the main contribution of our work",Reinforcement Learning
"We thank all the reviewers for their helpful feedback, and for being unanimously positive about the submission: R1:","1 ""The authors provided strong reasoning behind why a uniform shape is beneﬁcial""; R2: ""The paper is easy to follow""; 2 R3: ""Authors did enough experiments on different data sets and different neural networks""; R4: ""The authors have",Deep Learning
General response: We would like to thank the reviewers for their comments. We will incorporate all of the suggestions,1 in the ﬁnal revision. 2 Responses to comments of reviewer 1:,Computer Vision
Common.,"We thank the reviewers for their helpful feedback which has strengthened the paper. All reviewers noted 1 the strong empirical results, and thorough comparisons to other neural network veriﬁcation approaches. We also note 2",Deep Learning
Common Questions,"1 “Expert” policies. We now see how the term “expert” can be misleading. In the revision, we will replace it with “oracle” 2 and change the paper title to “Policy Improvement via Imitation of Multiple Oracles”. While we allow weaker oracle",Computer Vision
"Thanks for your valuable comments. Due to limited space, we can only respond to major concerns. And for other","1 suggestions like typos, will be carefully revised in the revision. 2 I would like to respond to some common questions ﬁrst.",Computer Vision
We thank all reviewers for their comments and acknowledgement of our contribution. All comments are very useful and,"1 will be addressed in greater details in the revision. For the theory part, we will add discussions on key results such as 2 Theorem 3 and Corollary 4, as Reviewer 3 suggested. For the experiments, we will add (i) more detailed illustrations",Computer Vision
"We thank the reviewers for their careful consideration and their feedback, our short replies are provided below.",1 General response for Reviewers 1 & 2. -“Can the results be extended to convex loss functions?”. 2 Response: We studied the convergence analysis of our proposed method for strongly-convex and non-convex settings,Optimization
"Thanks for the insightful and helpful reviews, which will signiﬁcantly improve our paper. Below, we refer to our Self","Validation Module as SVMo. R1, R2, R3 indicate to whom the concern belongs. All ﬁgures can be zoomed in for better view. Ground truth is in red, predictions are in blue, and predicted eye gaze point of the gaze-based model is in green. Novelty [R2]: First, we propose a novel, effective, ﬂexible (lines 43-48) and robust method of mutual self validation to model human foveated vision, inspired by both cognitive science and computer vision. Blurring has been used to",Computer Vision
Method,Segmentation Depth Surface Normal mIoU,Computer Vision
Response about the signiﬁcance and originality.,"Modelling the dynamics of multi-agent learning has long been 1 an important research topic, but an n-agent setting where n tends to inﬁnity has not been considered. All of the 2",Reinforcement Learning
Author Response for PHYRE: A New Benchmark for Physical Reasoning,"1 We thank the reviewers for their detailed and constructive comments. To recap, our submission introduces PHYRE, a 2 new environment for benchmarking aspects of physical reasoning in which agents are challenged to solve 2D physics",Reinforcement Learning
We would like to thank all the reviewers for their insightful comments and for ﬁnding this work interesting overall.,1 We’ll carefully incorporate your helpful suggestions into the paper revision. 2 Reviewer#1 Thank you for your very thoughtful feedback. We beneﬁt a lot from it. We agree that there has been,Computer Vision
We thank the reviewers for the constructive feedback and detailed comments which we integrate in the ﬁnal version.,1 R1/R2/R3: “comparison with [7] for boosted decision trees and to neural networks” 2 At submission time no code was available for [7] which is why we did not compare to them. Please note that we,Deep Learning
"Our paper presents an geometric interpretation for inverse reinforcement learning (IRL) with ﬁnite states and actions,",1 as well as a corresponding L1-regularized Support Vector Machine formulation with formal guarantees in sample 2 complexity and with regard to Bellman optimality. We thank the reviewers for their feedback and for bringing several,Reinforcement Learning
"We thank the reviewers for their time and insightful comments. We were able to address most of them, which helped","1 improve the paper. We focus on the major comments below, and minor ones will be addressed directly in the paper. 2 Direct supervision between the two source images [R1, 2, 4]. This is a viable approach; however, it does not",Computer Vision
"We appreciate the reviewer’s valuable comments, and we were glad to read the positive comments regarding the","1 technical motivation, idea, and our results. We also appreciate the thorough feedback for further improvements. We will 2 address those issues in a future revision of our work.",Computer Vision
We thank the reviewers for their feedback. We reply to the main points below:,"1 Usefulness of the method (R1, R3) and applicability of assumptions (R4): Actually, this work started precisely to 2 unblock the adoption of a real-world Computer Vision AutoML system: Users ﬁne-tune models selected from a large",Computer Vision
"First, we would like to thank the reviewers for their helpful feedback. Here, we address the main questions, and we will","1 clarify all of these points in any future revision. 2 Reviewers 1, 2, 3, and 4:",Computer Vision
We thank the reviewers for their insightful comments and suggestions. We ﬁrst reiterate the main goal and contributions.,"1 We asked (a) if having a 1/n neural code make neural networks more robust, and (b) how does the neural code 2 employed by the intermediate layers affect the robustness. To answer these neuroscience-inspired questions on neural",Deep Learning
Dear all reviewers: we highly appreciate your valuable comments and will reﬂect your comments in the revision.,"1 [R1] Interpretation of the shared component: [“...wouldn’t two brain areas that encode a particular stimulus, 2 but not necessarily “communicate ” with one another...exhibit a significant relationship? ”] We agree with the",Computer Vision
We thank all the reviewers for their positive comments and constructive suggestions. We will incorporate the suggested,"1 changes and add the relevant references in the ﬁnal revision, if accepted. Below, we address the primary questions. 2 Response To Reviewer #1",Computer Vision
"We thank all reviewers for their detailed and valuable feedback. In the following, we address the reviewers’ comments","1 and questions, which we will clarify in the ﬁnal revision. 2 Novelty of the joint model [R3] We agree with R3 that [3,37] pioneered gaze integration in NLP tasks, paving the",Computer Vision
"We thanks reviewers for their feedback. First, we address some common concerns.","1 Disparity between the region caption based queries in our experiments and the user queries in real scenario. 2 As emphasized in our manuscript (L53), leveraging region captions for weak supervision can been seen as one of the",Computer Vision
"Dear all reviewers, we highly appreciate your valuable comments and will reﬂect your comments in the revision.",1 » Revewer 1 2 » “1. I think more could be done on the experimental front. ... in better RL in a number of settings.”,Computer Vision
"We thank all reviewers for spending their valuable time reviewing our paper. We appreciate their insightful comments,","1 and will incorporate them in the revision. We now answer some speciﬁc question in detail. 2 Relaxation of the notion of equivalent subMDPs: The deﬁnition of ""equivalent subMDPs"" (Deﬁnition 2) requires",Computer Vision
"We thank the reviewers for their positive, kind, and constructive feedback! The two main points of criticism concerned","1 (1) the lack of neuroscience background information, and (2) missing discussion and comparison to prior work. Due to 2 page limitations, these points were insufﬁciently addressed. In a revision, we will provide additional details here as well",Computer Vision
"We would like to thank all reviewers evaluating the paper, and will fully address all the review concerns in the revision.","1 Re R#1: The given method improves upon Projection cGAN (PcGAN) in only some cases. From the current IS 2 and FID results, we are only inferior to PcGAN on the ImageNet dataset. Especially, our method is much better than",Computer Vision
"We genuinely appreciate all three reviewers’ (#1,#2,#3,#4) valuable suggestions to strengthen our paper. We have","1 addressed all raised questions below: conducting new experiments to compare with hand-designed optimizers (#1) 2 and on more complex optimizee architectures (#1,#3); clarifying the experiment’s observations (#2,#4); improving",Optimization
"We thank all the reviewers for their positive comments, and address their major questions and comments below.",1 Clariﬁcations will be added in the revision and we will keep improving our draft. 2 Reviewer #1 We thank the reviewer for the positive reviews. The remarks raised are addressed below.,Computer Vision
"Common issues: As per reviewers request, we compare with most recent SoA methods using ofﬁcial code with","1 the same metric. Results are shown in Table 1. We extend our work (CNN part) to use 4 stacks of HourGlass 2 modules with intermediate supervision, this gives improved performance as shown in Table 1, which clearly shows our",Computer Vision
R1.1...these analysis mainly come from the existing work...the novelty is very limited. We respectfully disagree.,"1 As pointed out by R2, R3, R4, and R5, this paper develops a novel global convergence framework that uniﬁes the 2 convergence of several policy gradient methods, whose novelty is summarized in Lines 210-212 and further explained",Reinforcement Learning
Thanks for your careful reading and positive feedback! We address major comments here (and the rest in the revision).,"1 Further discussion/interpretation, and implications for ML (R1 and R2) The 9th content page allows us to greatly 2 expand our discussion throughout the paper, and to add a conclusion section highlighting the following implications:",Computer Vision
General: Thank you for your feedback. The main motivation/intuition behind our approach is the excellent performance,"1 we achieved with U-Nets for image segmentation. The theoretical/conceptual contribution is to exploit the similarity 2 between sleep staging – and time series segmentation in general – and image segmentation. Still, U-Time is not simply",Computer Vision
"We thank all the reviewers for the time reading our paper! We will ﬁx all the minor issues, and below we only address","1 the main concerns. We quickly point out in our revision we have already extended the lower bound to all kernel methods, 2 not just correlation kernels. We plan to include that if the paper gets in.",Computer Vision
We would like to thank all referees for their appreciation of our results and the useful feedback. Below is our reply.,"1 Reviewer 1: Thank you for pointing us to the relevant references. Si et al. was made available only in July 2020 during 2 ICML, while we cited Hu et al. as Reference [17] in our paper. Our setting (including the loss function, the construction",Optimization
"Response to Rev. #1: (A) We have performed comparison with other end-to-end learning frameworks in Appendix F, Page 11, including","1 comparison with ‘differentiable MPC’. In this response, we also provide additional comparison with ‘differentiable MPC’ in Fig. 1. In 2 revision, we will move all comparisons to the primary text. (B) We try to unify the fundamental IRL, OC, SysID problems, as they can be",Computer Vision
"We thank the reviewers for their encouraging feedback, and suggestions for improvement.",1 The main contribution of the paper is a novel abstraction technique to reduce the state-space for output range analysis 2 of neural networks. Our approach is orthogonal to existing approaches in that it can be used in conjunction with,Deep Learning
"We thank all the reviewers for their insightful and encouraging comments, and will update revision to solve the issues.","1 To Reviewer #1. Consider channel number m = O(n2) and sample number n is much larger than depth h in NAS, 2 our learning rate (LR) is η = O(λ/√m/h3) = O(λ/n). It indeed improves LR requirement in [18-20] which analyze",Computer Vision
We thank the reviewers for their positive and helpful feedback. We are encouraged that they ﬁnd our method scalable,"1 (R1, R3), widely applicable (R3) and our handling of interpolation errors (R1, R2) and evaluation extensive (R1). In a 2 thorough revision we will include the reviewers’ suggestions. Speciﬁcally we will (i) improve the outline of the paper",Computer Vision
Thank you for the thorough reviews and insightful comments.,"1 Clariﬁcations We ﬁrst address some of the smaller points raised by the reviewers. R1, we clarify that the loss function 2",Optimization
Joint Semantic Mining for Weakly Supervised,"RGB-D Salient Object Detection Jingjing Li1,∗, Wei Ji1,∗( ), Qi Bi2, Cheng Yan3, Miao Zhang4, Yongri Piao4, Huchuan Lu4,5, Li Cheng1 1University of Alberta, Canada",Computer Vision
Not All Images are Worth 16x16 Words: Dynamic,"Transformers for Efﬁcient Image Recognition Yulin Wang1∗Rui Huang1∗ Shiji Song1 Zeyi Huang2 Gao Huang1,3† 1Department of Automation, BNRist, Tsinghua University, Beijing, China",Deep Learning
Generalized Depthwise-Separable Convolutions for,Adversarially Robust and Efﬁcient Neural Networks Hassan Dbouk & Naresh R. Shanbhag Department of Electrical and Computer Engineering University of Illinois at Urbana-Champaign,Deep Learning
A Provably Efﬁcient Model-Free Posterior Sampling,Method for Episodic Reinforcement Learning Christoph Dann Google Research Mehryar Mohri,Reinforcement Learning
SegFormer: Simple and Efﬁcient Design for Semantic,"Segmentation with Transformers Enze Xie1 Wenhai Wang2 Zhiding Yu3∗Anima Anandkumar3,4 Jose M. Alvarez3 Ping Luo1 1The University of Hong Kong 2Nanjing University 3NVIDIA 4Caltech xieenze@hku.hk, wangwenhai362@163.com,",Deep Learning
Residual Relaxation for,Multi-view Representation Learning Yifei Wang1 Zhengyang Geng2 Feng Jiang2,Deep Learning
"Below are the responses to major issues raised by the reviewers; other issues (ﬁgures, equations, nomenclature,","1 implementation and run-time details, code release) will be addressed in revision: 2 Primary contribution of this paper (reviewer 2 and 3) The reviewer comments were helpful here. We think the",Computer Vision
Do Vision Transformers See Like Convolutional,"Neural Networks? Maithra Raghu Google Research, Brain Team maithrar@gmail.com",Deep Learning
Optimization-Based Algebraic Multigrid Coarsening,Using Reinforcement Learning Ali Taghibakhshi Mechanical Science and Engineering University of Illinois at Urbana-Champaign,Reinforcement Learning
Delayed Propagation Transformer:,A Universal Computation Engine towards Practical Control in Cyber-Physical Systems Wenqing Zheng The University of Texas at Austin,Deep Learning
Explaining heterogeneity in medial entorhinal cortex,"with task-driven neural networks Aran Nayebi1,*, Alexander Attinger2, Malcolm G. Campbell2, Kiah Hardcastle2, Isabel I.C. Low1,2,7, Caitlin S. Mallory2, Gabriel C. Mel1, Ben Sorscher4, Alex H. Williams6,7, Surya Ganguli4,7,8, Lisa M. Giocomo2,7, and Daniel L.K. Yamins3,5,7",Deep Learning
Multi-View Representation Learning,"via Total Correlation Objective HyeongJoo Hwang, Geon-Hyeong Kim, Seunghoon Hong, Kee-Eung Kim KAIST {hjhwang, ghkim}@ai.kaist.ac.kr, {seunghoon.hong, kekim}@kaist.ac.kr",Deep Learning
FACMAC: Factored Multi-Agent Centralised,Policy Gradients Bei Peng∗† University of Liverpool Tabish Rashid∗,Reinforcement Learning
EDGE: Explaining Deep Reinforcement Learning,Policies Wenbo Guo The Pennsylvania State University wzg13@ist.psu.edu,Reinforcement Learning
We thank all the reviewers for their detailed and positive reviews on our manuscript. We respond to some of the,1 questions and comments below. A further round of polishing has been conducted to improve the quality of the paper. 2 1. Motivation and Practical Use Case of the Neighboring Reward Functions,Reinforcement Learning
Identiﬁability in inverse reinforcement learning,Haoyang Cao Alan Turing Institute hcao@turing.ac.uk Samuel N. Cohen,Reinforcement Learning
We would like to express our sincere gratitude to the reviewers for providing their valuable feedback. We are able to,"1 collectively address only major comments below, but we will thoroughly implement all the comments in a revision. 2 [R1,R2,R3,R4]-1 (Generalization to C clusters and G groups): In fact, we could derive the minimal sample complexity",Computer Vision
To R #1 and R #2 for dual submission concerns: Although both papers are among the ﬁrst to explore Transformer,"1 in time series forecasting and achieve SOTA results, these two papers investigate different problems of time series 2 with Transformer (long-term dependencies & memory V.S. abrupt changes).  As mentioned by R #3, this paper",Deep Learning
Provably Efﬁcient Black-Box Action Poisoning,"Attacks Against Reinforcement Learning Guanlin Liu, Lifeng Lai Department of Electrical and Computer Engineering University of California, Davis",Reinforcement Learning
We thank all the reviewers for their valueable suggestions. Typos will be ﬁxed and related works will be revised.,"1 R1Q1: No DIEN results on product dataset. Necessary to give reasons. 2 R1A1: In preliminary studies, DIEN performs worse than Transformer on product dataset (consists with Tab1). We did",Deep Learning
Thank you to the reviewers for their helpful comments.,1 Reviewer #3 2 Regarding afﬁne relationships between positions: we agree that a transformer’s layers do not produce simple afﬁne,Deep Learning
We thank the reviewers for the positive and constructive comments. Our detailed responses are below.,"1 R2. We are grateful to the reviewer for the comments and suggested reference, which we will discuss in the revision. The 2 idea of learning hyperparameter importance bears interesting connections to our work, and is an alternative viewpoint",Computer Vision
"First, we thank the reviewers for their detailed, constructive, and positive feedback on the paper. We are happy to see","1 the they appreciate our contributions in proposing a method that is “mathematically sound” [R1], “simple and elegant” 2 [R3], and “enjoyable to read” [R4], while addressing “an important topic in machine learning, computer vision and",Computer Vision
1. Details about hyper-parameter tuning: All reviewers asked about the details of our “grid search” algorithm for,"1 hyper-parameters t and λ, which is omitted in our paper. So we describe it in Algorithm 1 and will add it in the revision 2 of our paper. The grid search aims to ﬁnd hyper-parameters that lead to a FLOPs reduction F ∈(F ∗−δ, F ∗+ δ),",Computer Vision
"We thank all the reviewers for providing constructive feedback. First, we hope to bring a new theoretical result to the",1 reviewers’ attention. We can now prove that Algorithm 1 is guaranteed to converge locally whenever 0 < α < 2. 2 We will include this new result in the revision.,Computer Vision
We would like to sincerely thank all our reviewers for their valuable feedback and insightful comments. We are,"1 committed to doing our best in addressing their concerns and suggestions in the ﬁnal version of the paper. We would 2 like to reiterate that apart from making the suggested clarifying revisions to our paper, we will release all of the datasets,",Computer Vision
We thank all four reviewers for their constructive comments. We respond to each reviewer’s comments separately below.,"1 We also report some results from new experiments suggested by the reviewers. 2 R1: (1) More context from computer vision: We thank the reviewer for suggesting these references, which we will",Computer Vision
"All: We thank the reviewers for their insightful feedback! We feel encouraged that they (R1, R3, R4) appreciate the","1 fact that our method achieves SOTA in En-De, En-Fr WMT’14 translation tasks and also outperforms the baselines 2 (e.g., Scaled Transformer) signiﬁcantly (1-2 BLEU) in 8 other translation tasks in IWSLT and Flores (low-resource)",Deep Learning
We thank the reviewers for their constructive feedback and their appreciation of our experiments on this paper. The,"1 suggestions about adding more model variations are helpful; we will include more model variations (Alexnet, ResNet, 2 and different initializations) in the revision. We have already performed comparisons of many architectures with the",Computer Vision
"We thank the reviewers for the thoughtful comments and attempt to address their questions, space permitting.","1 All reviewers: R1 and R2 correctly point out that relating intermediate representations in neural networks to brain 2 activity has been previously explored (as we also state in L53-54). However, previous works make key untested",Deep Learning
"We thank the reviewers for their meaningful and valuable comments, which help to improve the quality of our work.","1 Training with few errors [R1, R2, R3]: Given the small number of errors available to train ConﬁdNet due to deep 2 neural network (DNN) over-ﬁtting, one common suggestion from reviewers is to use hold-out data. We performed",Deep Learning
"We thank the reviewers for their detailed feedback, and especially appreciate the suggestions on future research","1 directions for C-RBP. Our revision will reﬂect the reviewers’ comments, which we believe greatly improve its clarity. 2 Future directions R1, R2, R4: Each of the reviewers offered suggestions for future directions for our C-RBP method.",Computer Vision
We thank the reviewers for their positive feedback and suggestions. Below we address the major points raised. We will,1 also be sure to incorporate the smaller suggested edits in the ﬁnal revision. 2 Reviewer 1,Computer Vision
"We thank the reviewers for their time and effort, and for the helpful feedback!","1 For those reviewers that we have answers: we hope our comments alleviate your concerns and, in that case, potentially 2 warrant a suitable revision of your reviews, thank you!",Computer Vision
We thank the reviewers for their constructive comments and share their enthusiasm about combining techniques,"1 from non-parametric Bayes with neural networks in order to tackle problems such as negative transfer and adaptive 2 complexity. We brieﬂy state our contributions in contrast to prior work (p.w.) in meta-, continual, and online learning:",Deep Learning
"We would like to thank the reviewers for their useful, detailed feedback! We will update the paper with the suggested","1 minor revisions regarding typos and presentation improvements, and respond to individual reviewers comments below. 2 Reviewer #1:",Computer Vision
We thank the reviewers for the constructive comments and suggestions. Below we address the main,"1 issues. We will ﬁx all other minor issues in the revised paper. 2 R1, R3: Dance unit. We will elaborate on the dance units, which are not a simple division of",Computer Vision
From voxels to pixels and back: Self-supervision in natural-image reconstruction from fMRI,1 We thank the reviewers for their comments and endorsements. Below are our answers to the main questions/concerns. 2 R1: Training on test-fMRI samples – not convinced the approach is valid. We understand the reviewer’s concern.,Computer Vision
Thank you for the insightful comments from all reviewers. Those are very helpful to improve our submission.,"1 Additional baselines [R1-A1] We agree that [TaBERT & TabNet] and VIME have common concepts - the pretext task 2 for self-supervised learning (self-SL) is recovering masked data. However, there are two major differences as well: (1)",Deep Learning
"(R1, R2, R3) We will correct all typos, grammatical errors, and misleading notations (e.g. Eq. 4) in the revision. We",1 will also clarify ambiguous terms and cross-dataset evaluations. 2 (R1) Side-to-side video comparison. We will add side-to-side video comparison in the revision.,Computer Vision
Author Rebuttal for NeurIPS 2019 Submission #964,1 We thank all the reviewers for their positive comments and valuable suggestions. This paper presents a linear-time 2 learnable tree ﬁlter to capture long-range dependencies while preserving structural details for semantic segmentation.,Computer Vision
We really appreciate all reviewers for their careful reviews and constructive comments. We are pleased that all reviewers,"1 ﬁnd our work innovative and interesting. In the following, we highlight the primary issues and questions proposed by 2 the reviewers. Remaining minor comments and suggestions will also be incorporated in the revision to polish our paper.",Computer Vision
We thank the reviewers for their consideration of our paper and their insightful suggestions that,"1 will be included in the revision. The consensus appears to be that this is a “well written” (R1, R2, 2 R3, R4) paper that introduces a “simple yet effective module” (R1) to solve an “important problem”",Computer Vision
Author response for Continual Unsupervised Representation Learning,"1 We would like to thank the reviewers for their insightful and constructive comments, which will certainly help to 2 strengthen the paper. We have systematically addressed each of their concerns, which we summarise below.",Deep Learning
"We thank the reviewers for their time and feedback. To our knowledge, our work provides the ﬁrst practical algorithm",1 with provable iteration complexity for solving nonconvex optimization problems with nonlinear constraints which has 2 numerous applications in machine learning. We argue that the proposed framework will be a staple for many such,Optimization
We thank all reviewers for their comments and we will make every effort to address all comments in the revision.,1 R1 and R5: Rates/ﬁnite sample bounds. One of main difﬁculties in ﬁnding a rate of convergence of our estimator 2 is precisely characterizing how convergence of the mixture components (l. 192) depends on the convergence of the,Computer Vision
"We thank the reviewers for the detailed and insightful reviews. As the reviewers noted, our work 1) contributes to “a",1 deeper understanding of NTK and its limitations” and 2) develops novel analysis tools and techniques. We answer 2 reviewers’ questions below and will incorporate feedback into the ﬁnal revision.,Computer Vision
We would like to thank the reviewers for their helpful feedback; we will use it to signiﬁcantly improve our manuscript.,"1 Reviewer 2 2 We would like to give a high level summary of our paper for clarity. Neural networks are hard to train and techniques,",Deep Learning
"We thank the reviewers for their time, their valuable and encouraging feedback, and their recommendations for",1 improvement. We remain conﬁdent that our work is of strong interest to the NeurIPS community and easily can 2 incorporate the suggested changes in a revision for the conference. Answers to speciﬁc comments appear below.,Computer Vision
"We thank all reviewers for their efforts in reviewing our paper, and for the helpful comments and suggestions.","1 Reviewer 2: 2 • “Id like to see some statistical properties of these new loss functions, and how they are compared to the",Optimization
We thank all the reviewers for their insightful comments and for the acknowledgement of our contributions in this work.,1 We intend to do our best to incorporate their feedback into our revision. Here we would like to use this opportunity to 2 clarify some important aspects of our work ﬁrst and respond to the remaining points raised by each reviewer.,Computer Vision
We thank the reviewers for their thoughtful feedback. We will make sure to incorporate all minor editorial recom-,1 mendations in the next revision of our paper. Below we explain our results at a high level and answer the reviewers’ 2 questions. We consider two fundamental problems in statistical hypothesis testing: testing independence of a bivariate,Computer Vision
Reviewer 1 [The] methodology combines multiple different ideas in causal inference (multi-headed deep learning,"1 models and targeted learning) in a novel way, and their empirical evaluation seems very strong. Thank you for your 2",Deep Learning
On Robustness of Principal Component Regression:,Author Response We begin by thanking all reviewers for their extremely encouraging and helpful responses. We intend to incorporate their feedback into our revision as best as possible. Below we respond to speciﬁc points raised by each reviewer.,Computer Vision
We would like to thank the reviewers for their thoughtful advice and feedback. Reviewers raised concerns about the,"1 applicability of this work to NeurIPS. As AD is a fundamental computation required to train neural networks, perform 2 Bayesian inference, and run many other ML algorithms, the AD tool-maker community has been well-represented at",Deep Learning
We thank all the reviewers for their insightful comments! All the responses will be incorporated into our revision.,1 R1: (1) We designed a variational graph isomorphism network to injectively encode structural information of networks 2 in the latent space and accurately remap to original structures after latent space optimization. (2) The observations are,Computer Vision
Thank you all for the helpful reviews. We ﬁrst address concerns shared among reviewers:,"1 Experiments (real world networks): The Segmentation_11 network is a real-world network taken from the UAI Prob- 2 abilistic Inference competition (2006 to 2014). It is a factor graph that was used to do image segmentation/classiﬁcation,",Computer Vision
We thank the reviewers for their thoughtful and detailed comments. Brief replies follow below.,"1 R1) Input dimensionality: P-GAMs have similar scaling with the number of input dimensions as traditional GLMs. 2 Nonetheless, using P-GAMs makes most sense when the inputs are task or cognitive variables; we don’t envision our",Computer Vision
"We thank all of the reviewers for their careful reading of our work. In particular, several reviews made helpful","1 suggestions for how we could improve the presentation, which we will implement in the next revision: 2 • We will add more intuition for our construction, to address the comment that our presentation is too dense. In",Computer Vision
We thank the reviewers for their valuable time and comments. All suggestions will be incorporated in the next revision.,"1 Before addressing each of the reviewers’ individual comments as best as we can, we want to stress the fact that we 2 do provide extensive and comprehensive experimental results, designed to validate the theoretical results, rather than",Computer Vision
Compare with the SOTA.,We carry out further experiments on Transformer and list the results in Table 1. We ﬁnd 1 that KerBS can also bring performance gains to Transformer models. 2,Deep Learning
We thank the reviewers for their valuable comments and for pointing out the typos and clarity issues. We will revise,"1 accordingly. We ﬁrst explain the novelty and signiﬁcance of our work and then answer the questions of each reviewer. 2 (Novelty and Signiﬁcance.) Our novel bilevel optimization formulation of actor-critic works for general RL problems,",Reinforcement Learning
"Response to Reviewer #1: Thank you for the careful reading and feedback. In a revision, we will address the detailed",1 comments: 2 1. We will clarify the discussion around Lemma 3 to reﬂect that activation regions and linear regions are typically,Computer Vision
We thank all reviewers for their constructive feedback! We are encouraged that they found our contribution interesting,"1 (R4), addressing a hard problem that is important in robotics (R4), while also extremely relevant to NeurIPS (R1) 2 in the area of robot control from language and vision (R2). Our extensive experiments (R4) demonstrate impressive",Computer Vision
We thank the reviewers for their time and comments. Mutual information has emerged has an indispensable tool in,"1 representation learning and we share the reviewers’ enthusiasm to explore further implications of our method, the ﬁrst to 2 provide an analytic expression for the compression rate for arbitrary input distributions. Some reviews express concern",Deep Learning
We thank the reviewers for their constructive feedback on our paper. We especially appreciate our reviewers’ conviction,"1 that our implementation will be a widely used tool for embedding convex optimization problems in end-to-end learning 2 models. By combining DCP, the residual approach to differentiation through a cone solver, and the proposed ASA form",Optimization
We thank all reviewers for their constructive and valuable comments.,1 (R1) Typos and codes. We will ﬁx typos in the revision and make the code publicly available. 2 (R1&R4) Evidence for strength of different object representations. We test the detailed metrics for 4 typical models,Computer Vision
We thank the reviewers for their comments and will do our best to address them in our paper.,"1 R1, comparison to RL with communications as actions. We agree that the multi-agent communication problem can 2 be formulated as an MDP where decisions about which agents to communicate with is part of the action. We performed",Reinforcement Learning
We thank the reviewers for acknowledging our contributions and for providing valuable feedback.,"1 To R#1: Transformer latency: For MNIST experiments, TensorFlow reports that the LeNet-5 BNN requires 2 10,906,677 FLOPS and the WGWIN-GP generator requires 9,292,938 FLOPS. The additional cost of the rejec-",Deep Learning
"We thank the reviewers sincerely for their valuable feedback, which has provided us with an achievable plan to","1 improve the clarity and impact of the paper with a revision as outlined below. We were particularly encouraged by the 2 predominantly positive and supportive remarks (e.g., R1: ""The result of fair resource allocation in continuous time is",Computer Vision
We thank all reviewers for their encouraging and constructive feedback.,"1 Rev#1: We thank the reviewer for their suggestion to tease apart the impact of architectural decisions, have a clearer 2 elaboration of the fusion task, and include full neural network model formulation. We will include additional details",Deep Learning
We would like to thank the reviewers for their helpful comments. We will revise accordingly in the revision.,"1 Reviewer 1: (General RKHS) Our KOVI algorithm can be applied for any RKHS in generalized. As shown in the 2 discussion below Theorem 4.3, we can set β = O(H√log N∞) and obtain a H2√log N∞γT T regret, where N∞is",Computer Vision
"We thank all four reviewers’ time, effort, and valuable suggestions. We will (I) add the suggested experiments and","1 comparisons, (II) explain more intuition behind various design, (III) do our best to proofread our paper in revision. 2 ———————————————————To Reviewer #2 (R2)———————————————————",Computer Vision
We thank all three reviewers for their time and comments. Their suggestions will help us clarify the contributions of our,"1 work as we incorporate them in the next revision of our paper. 2 In the following, we respond to several speciﬁc points raised by the reviewers.",Computer Vision
On the Expressive Power of Deep Polynomial Neural Networks,1 We thank the reviewers for their positive and useful comments. One shared concern among the reviewers seems to 2 be that our study of the exact functional space and its dimension might not be directly helpful for understanding the,Deep Learning
•,"1. Privacy preserving. R4/R3: the features maps might leak privacy; R1: privacy property has not been described. 1 We will discuss the privacy concerns in our revision. 1) our work does not focus on privacy-preserving techniques, but 2",Computer Vision
"Reviewers, thank you for your careful analyses of our paper.","1 We would like to clarify the value of our work for self-supervised learning, input corruption robustness, adversarial 2 examples, label corruption robustness, and out-of-distribution detection. A preliminary version of this work has been",Deep Learning
Better Exploration with Optimistic Actor-Critic: Author Response,1 Fig. 1: Sample efﬁciency Fig. 2: Optimism ablation (βUB) Fig. 3: Magnitude of shift.,Reinforcement Learning
We thank all reviewers for their feedback and insightful comments. We are pleased to see our contributions warmly,"1 received: ""It’s inspiring to see the fusion of interactions and vision in this paper"" (R3); ""The addressed problem of 2 reconstructing 3D shapes, with hand-object interaction, is novel and interesting"" (R4); and ""Overall, I really liked the",Computer Vision
We sincerely thank reviewers for their insightful feedback! We are encouraged that reviewers ﬁnd our method novel,"1 (R2,R3) and analysis insightful (R3). All reviewers (R1,R2,R3,R4) agreed that our method achieved signiﬁcant 2 improvements in a variety of tasks/settings (image classiﬁcation, object detection, instance segmentation, adversarial",Computer Vision
General comments.,We thank the Reviewers for their detailed reviews and the feedback regarding the theoretical 1 study of rational neural networks (NNs) and their promising applications. Reviewer 4 noted that the introduction of 2,Deep Learning
"We appreciate all reviewers’ valuable comments. We shall address the concerns raised point by point, as follows.","1 To R1 & R2: 1. The qualitative results are not very satisfying: In fact, there is very little supervision used in our 2 method and so it is very challenging. Firstly, we do not use ground-truth 3D texture supervision. Second, the human",Computer Vision
We sincerely thank all the reviewers for their feedback indicating that we present an innovative work that could have a,"1 wide impact (R1), and for appreciating the overall idea and emphasizing the effectiveness of our method (R2, R3). We 2 strongly believe that combining the advantages of more classical inference methods with those of Deep Learning may",Deep Learning
"We thank the reviewers for their time and comments. Due to space limitations we could only address major points, but",1 we’ll try to reﬂect all advice in future revisions. 2 Response to Reviewer #1,Computer Vision
Response to reviewer 1. Weakness 1: The result for neural network is an upper bound which may not be tight. Indeed:,"1 Theorem 4 is just an upper bound on the approximation error, and a lower bound for NN is currently missing. The 2 upper bound is sufﬁcient to prove a separation result for κ large enough. While the upper bound is not tight pointwise",Deep Learning
"We thank the reviewers for their useful feedback. Overall, we see a positive reception of our work. Reviewer 1 points","1 out that the paper is “well-written”, reviewer 4 says that “the paper has an originality” and notices the “very nice 2 results on the MRI reconstruction task”, and reviewer 5 ﬁnds that “this paper would be very useful for Computer Vision",Computer Vision
We sincerely thank the three reviewers for their constructive comments and supports.,1 Response to Reviewer #1: 2 Q1: Compressing on the user part. A: GPUs are essential to doing effective deep learning. Compared with setting up,Deep Learning
Reviewer 1. We appreciate R1’s recognition of the novelty of our contribution to MARL and the potential impact on a,"1 range of problems. We address R1’s two concerns below. Regarding our chosen baselines, we note that baselines 2 we include represent three major existing categories: 1) policy gradient and actor-critic with discrete or continuous",Reinforcement Learning
"To Reviewer #2: Thanks for recognising the novelty, clarity and promising results of our work.",1 Reproducibility: Please note that our supplemental material contains both the complete architecture of the agent and 2 detailed pseudo-code for the algorithm. We’ll add a reference to the appendix in the main text of the paper.,Reinforcement Learning
We thank all reviewers for their useful feedback and acknowledgement of our contribution. All comments will be,1 addressed in greater details in the revision. We ﬁrst answer some common questions brought up by reviewers. 2 Numerical illustrations: Thanks for the suggestion! We agree with reviewers that it is useful to provide some numerical,Computer Vision
We thank the reviewers for the detailed comments. We will address all the minor issues and do not discuss them,1 individually here. We will also add high-level pictures and proof sketches in the revision. 2 Novelty and Originality: We would like to ﬁrst describe brieﬂy the key differences between our work and the existing,Computer Vision
We would like to thank the reviewers for their feedback and time.,"1 Signiﬁcance of the work. R2 and R3 are concerned about the signiﬁcance of the work. We respectfully disagree with 2 the opinion that the signiﬁcance is low/mixed. The Bayesian deep learning (BDL) community, which is our target",Deep Learning
"We are grateful for all the reviewers for their constructive feedback, which will undoubtedly improve the quality of","1 the manuscript. As four reviewers acknowledge, we present a novel segmentation approach to learning robustly in the 2 presence of large expert disagreement in annotations, and demonstrate its utility in a range of datasets from medical",Computer Vision
We would like to thank the reviewers for their thorough evaluations and for bringing to our attention some missing,"1 citations and typos. We answer speciﬁc questions raised by the reviewers, below. 2 Performance w.r.t. number of agents (R1). We discuss how our methods scale with the number of agents in Appendix",Reinforcement Learning
"We propose a decentralized Bayesian learning algorithm when the data set X is held disjointly over n agents, i.e.,",1 X = Sn i=1 Xi with Xi T Xj = ∅for j ̸= i. Thus the posterior satisﬁes p(w|X) = Qn,Reinforcement Learning
We’d like to express our gratitude towards all the reviewers who recognized the novelties of the proposed intermediate,"1 representation for 3D object detection and the template-based prediction, as well as the signiﬁcantly improved 2 performance. We further appreciate R3 for commenting that “predicting 3D properties by their projections is the right",Computer Vision
"We thank all reviewers for their valuable comments and suggestions. Here we focus on clarifying major concerns, and","1 will address all minor points (ﬁx notations, typos, and improve legibility for tables and ﬁgures) in our next revision. 2 [R1] 1) Larger sample size: In Table A, we repeat our experiments on 5000 test examples for each dataset (or the",Computer Vision
We thank all reviewers for the constructive comments! We now respond to common and individual comments.,"1 Common: Q1: On musical motivation and background. In the revision, we will give more introduction and references. 2 A brief one: Counterpoint [1] is an essential and unique concept in Western music theory. Traditional Chinese music",Computer Vision
We thank the reviewers for their careful consideration of our paper and for the useful feedback. We are happy to see,"1 that the reviewers ﬁnd that the paper is “well-written”, contributes a “cool, instructive result”, and that it “tackles a very 2 important question on representation learning and provides interesting new insights about it”. However, there appear",Deep Learning
Author Response for “Stochastic Normalization”,"1 We thank all reviewers for insightful and professional comments. In general, reviewers ﬁnd the paper well written, the 2 topic important, and the method novel. Major concerns are addressed here, which will be incorporated to the revision.",Computer Vision
We thank the reviewers for their constructive feedback.,"1 The use of LSTMs instead of 3D CNNs [R1, R2, R3]. We use LSTMs as an “agent” not only to make classiﬁcation 2 predictions but more importantly to make sequential gating decisions—dynamically determine whether to compute",Reinforcement Learning
We thank all reviewers for their valuable comments and suggestions. We’ll incorporate suggestions and clariﬁcations in,1 the revision. We ﬁrst address a shared point (by Reviewer 1 and 2) and then respond to each reviewer respectively. 2 Further ablation about sub-graphs (R1 and R2). We have provided an ablation study about the main components of,Computer Vision
Response to Reviewer #1,"1 The goal of this paper is to determine whether neural networks (NN) are equivalent to kernel methods or not. While at 2 ﬁrst sight one would guess that neural networks are more powerful than ‘simple’ kernel methods, the recently developed",Deep Learning
"We thank the reviewers for valuable feedback. Before addressing individual comments, we clarify common concerns.","1 Evaluation Protocol: The most ambitious aim of self-supervised learning is to create universal visual representations 2 that do not require end-to-end ﬁne-tuning, but are instead portable to new tasks merely through additional of a shallow",Deep Learning
Reviewer 1,"We understand the reviewer concerns, but point that the strong duality of constrained RL is in fact not 1 a trivial result. Indeed, though Slater’s condition is often used in the context of convex optimization and does imply 2",Optimization
"We would like to thank all reviewers for reading our paper and providing constructive comments. Upon acceptance, we","1 will proofread and ﬁx all editorial issues. Below we ﬁrst address a few common concerns. 2 Learning mode and intervention mode. In most cases, the game designer is expected to ﬁrst learn about the agents",Reinforcement Learning
We thank the reviewers for their valuable and constructive feedback. We will incorporate the suggestions in the next,1 revision. Our responses below. 2 Reviewer 2:,Computer Vision
Thank you for the insightful comments. We will make sure to address all requests for elucidation in the revision.,"1 R1 and R2: Single image evaluation: Our main motivation is that of single sample video generation. However, 2",Computer Vision
We thank the reviewers for their comments and valuable feedback. In the following we address their questions:,1 2 Reviewer1: We thank the Reviewer for several useful suggestions that we will gladly include in the revisions. 3,Computer Vision
"R1Q1: Relationship with HRNET: Our work is inspired by the ﬁrst work which has been cited in the paper, but we","1 missed the second work which will be reviewed and credited in the revision. Noticed that, HRNET is a handcrafted 2 network, which does not abstract the three modules (i.e., building a search space) for NAS like this paper does.",Computer Vision
We thank the reviewers for their constructive feedback. Our study explores how the intrinsic dimension (ID) of data,1 manifolds varies across the layers of state-of-the-art deep neural networks (DNNs). Our ﬁndings can be summarized as 2 follows: 1) the ID follows a “hunchback” shape across the layers of a trained DNN (Fig. 3); 2) data representations,Deep Learning
"We would like to thank the reviewers for their feedback. We will add the suggested references, clariﬁcations from our","1 answers below, and further qualitative experiments in the camera-ready revision. 2 [R1] Which parts of the model in §4 constitute the baseline? The AST-based decoder described in §4.1 constitutes",Computer Vision
Response to R1: We thank you for the enthusiastic review and thoughtful comments that we will address in our,1 revision. 2 Response to R2: We thank you for the positive review.,Computer Vision
Paper Title: Learning Object Bounding Boxes for 3D Instance Segmentation on Point Clouds,1 We would like to thank all reviewers for their very insightful comments and address them in the following. 2 1. Comparison of computation efﬁciency. Table 1 compares the time consumption of four existing approaches using,Computer Vision
Our work “establishes interpretations of SGD and Adam-family optimizers from a Bayesian ﬁltering perspective” (R3).,1 It is “the ﬁrst to demonstrate how viewing optimization as Bayesian inference requires modeling temporal dynamics” 2 (R4) and results in an algorithm that is “easy to implement and is computationally efﬁcient” (R4) and “beneﬁts from,Optimization
We appreciate the valuable comments from the reviewers. We will revise them accordingly.,"1 Novelty of DAPG and Brief History of Decentralized Proximal Gradient Descent 2 The novelty of DAPG is the main concern of reviewers because DAPG is closely related to Mudag [25]. However,",Optimization
General Response Thanks for all reviewers for your insightful comments. We appreciate the reviewers for your,"1 commendation for the simplicity, intuitiveness and effectiveness of our method. We will carefully address your 2 suggestions on typos, writing style and missing citations in the revision.",Computer Vision
To Reviewer #1. We appreciate your positive feedback and will revise our presentation accordingly. Our bounds can,"1 help hyper-parameter selection in graph representation learning (a running example about BlogCatalog can be found in 2 our response to Reviewer #4). Prior to this work, the walk length of DeepWalk has to be selected by cross-validation.",Deep Learning
We thank all the reviewers for their reviews! We will address the excellent writing/presentation-related suggestions in,"1 revision. Here we focus on clarifying questions about the framework, surveys, and results. 2 Re R1: Relevance and signiﬁcance of results. We believe that the paper is appropriate for NeurIPS because it speaks",Computer Vision
"We thank the reviewers for the comments. In this work, we proposed a model to encourage the inter-neuron communica-","1 tion at the same layer (R1, R2, R3), and showed better performance than baselines and SE-Nets on image classiﬁcation, 2 semantic segmentation and object detection (R1, R2, R3). To demonstrate the effectiveness of our model, we did many",Computer Vision
We thank the four reviewers for their constructive comments. The following are our responses to reviewers’ comments.,"1 (We use T, SHT, NNP, and MS to denote triplet, semihard triplet, normalized n-pair, and multi-similarity, respectively.) 2 To Reviewer #2 Q1: Some formulations are confusing. R1: Thanks. We will rewrite the formulations in the revision.",Computer Vision
We thank the reviewers for their feedback. Below we list the respective revisions that will be made (R = Reviewer).,"1 Conceptual and intuitive introduction to transformation learning (R1,R2,R3) We will completely revise Section 2 2 which will now open with the following paragraph: ""Next, we turn our attention to learning to detect transformations",Computer Vision
We thank all the reviewers for helpful suggestions. We will incorporate the following analysis into our revision.,"1 (R1) Qualitative analysis via attention patterns. We compared the attention pattern of BERT and XLNet without 2 ﬁnetuning. Firstly, we found 4 typical patterns shared by both, as shown in Fig. 1.",Computer Vision
"To Reviewer1: 1. Method simplistic, places too much constraints on activation (only ReLU-like activations).","1 We believe the proposed H-regularization is novel and by no means simplistic. It is well suited for one-class learning. 2 ReLU-like activations are widely used, e.g., Transformer, Resnet, etc. It does not affect the application of our method.",Deep Learning
We thanks the reviewers for their feedback. We now proceed to reply to their comments.,"1 Number of Samples for Complete Graph? (R1): In this case there is no network error and all of the agents iterates 2 are identical to centralised single-machine Gradient Descent (GD) applied to all of the samples within the network,",Reinforcement Learning
We sincerely thank all reviewers for their feedback. We present an image reference game where it is necessary to model,"1 other agents’ understanding of task-related concepts to succeed. The reviewers indicate that our framework is shown 2 through a technically sound experimental evaluation (R1) to be capable of modeling other agents’ expertise (R2,R3),",Reinforcement Learning
Humans,RL Agents Persistence (r) Persistence (q) Search Temp. (T ),Reinforcement Learning
"We are glad that all reviewers appreciated the soundness of our work, the importance of the hidden stratiﬁcation (HS)","1 problem we address, and the extensiveness of our evaluations. We thank the reviewers for their thoughtful questions 2 and helpful feedback to improve our paper, and we will incorporate the responses below into our revision.",Computer Vision
We thank the reviewers for their valuable comments. We reply to each outstanding point below.,"1 REVIEWER 1. R. Extension to meta-reinforcement learning. A. One starting point in this direction would be to 2 consider the simpliﬁed setting of contextual bandits with linear reward functions. However, even in this case the",Reinforcement Learning
"We thank all the reviewers for the helpful comments and questions. Before moving on to answer reviewers’ questions,","1 we ﬁrst clarify the main contributions and motivations of our paper. 2 The goal of the paper is to better understand neural network optimization, especially the interactions between algorithmic",Deep Learning
===Reviewer 1===,"1 The execution time for inference is not provided in the paper. It might be a problem in cases like web marketing, where 2 the agents must make decisions in millisecond order. Median inference time to select an action is between 5 to 8 ms",Reinforcement Learning
We want to thank the reviewers for their thorough comments and suggestions for improving the manuscript. We have,"1 inlined responses to the major points below, and will address all minor points in our next revision as well. 2 (R1) Assumptions While we cannot establish formal guarantees when constructing our “robust dataset” in Section",Computer Vision
"I would like to thank the reviewers for their thorough and constructive comments, and I am conﬁdent that all of the","1 feedback can be easily incorporated in a revision. The comments broadly fell into three areas, which I address below: 1) 2 an application of the non-overlapping mixtures trick (NOMT) to real data; 2) a comparison of the NOMT to a broader",Computer Vision
We thank the reviewers for their careful reading and thoughtful feedback regarding our manuscript. Many of these,"1 comments will be incorporated in our latest revision. We appreciate the opportunity to clarify some points and address 2 some of the reviewers’ concerns, which substantially consist of requests for more extensive background comparisons",Computer Vision
We are grateful to the reviewers for their valuable feedback. They have clearly understood the paper well; we agree,"1 with the assessment of both the strengths and weaknesses of the paper. In our revision, we will try our best to address 2 the concerns and execute the suggestions.",Computer Vision
"We thank the reviewers for their comments and feedback. We believe issues of language, terminology, and organization",1 can be fully addressed in the revision. We address speciﬁc issues below. 2 1,Computer Vision
We thank the reviewers for their constructive and valuable comments. The resulting revisions and additional experiments,"1 signiﬁcantly strengthened the paper. In the following three sections we summarise and address all major concerns in 2 detail. All other comments will be addressed as well, but not discussed here due to space limitations.",Computer Vision
Thanks for the reviews! Response to individual reviewers are below.,"1 R1. You are right that the contribution is theoretical, but our formulation of the representation learning problem and the 2",Deep Learning
We thank the reviewers for the constructive feedback. Following are response to some of the comments.,"1 Innovation is not huge (R1, R2, R4) The novelty of the proposed SimpleTOD is based on simplifying task-oriented 2 dialogue as a causal language modeling. Moreover, we show that using a simpliﬁed input sequence deﬁnition, special",Natural Language Processing
"We thank all reviewers for their time and appreciate the thoughtful feedback. Below, we address the main comments.","1 Reviewer 1: ""In the example given by the author, the agent is allowed to run until it reaches a terminal state during 2 training time, but during test time is cut off after h timesteps.""",Reinforcement Learning
We would like to thank our reviewers for their constructive comments.,"1 R1: Not ﬁrst to look at full meshes. Cite Sminchescu et al., ...Soften claims? Thank you for the references, which 2 we will add. Accordingly, we will limit our claim to deep learning approaches for human pose reconstruction. R1, R3:",Deep Learning
Paper ID 10791,"Title: Information-Theoretic Task Selection for Meta-Reinforcement Learning We thank all the reviewers for their thoughtful feedback. Our response can be found below,  organized by review. R1",Reinforcement Learning
"We thank the reviewers for their time, their valuable and encouraging feedback, and their recommendations for",1 improvement. We remain conﬁdent that our work is of strong interest to the NeurIPS community and easily can 2 incorporate the suggested changes in a revision for the conference. Answers to speciﬁc comments appear below.,Computer Vision
We thank the reviewers for their valuable comments. We will add the suggested clariﬁcations to the paper and appendix.,"1 *Reviewer 1 Thank you. We’ll add more explanation about supervision, proxy graph, prior work, etc as suggested. 2 Evaluation: Internal travel during the graph jumps are also included in the path and path length (following the standard",Computer Vision
"Dear reviewers and area chairs,","1 Thank you for the careful reading of our manuscript and for the helpful comments and suggestions. We will address all 2 of the smaller suggestions for improving the next revision of the manuscript. Below, we respond to some of the more",Computer Vision
We greatly appreciate the reviewers for the time and expertise they have invested in the reviews. This essay focuses on,"1 addressing the main concerns raised by each reviewer. Due to the page limit, we will not be able to mention and answer 2 all the questions. However, we would like to thank the reviewers for every observation and suggestions for revision and",Computer Vision
We are grateful for the reviewers’ constructive feedback.,"1 Novelty & limitations: Reviewer 4 (R4) correctly points out that there exists a rich literature on meta-learning learning 2 rules for neural networks, and we did not adequately cite this literature. Regarding the high-level claims we made that",Deep Learning
"We thank all the reviewers for their insightful and encouraging comments, and will update revision to solve the issues.","1 To Reviewer #2. Our main goal is to theoretically show the stronger escaping ability of SGD over Adam at the same 2 basin. For the by-product, i.e. relation between Radon measure and escaping time, we construct f =min(x2, a(x −1)2)",Computer Vision
"We ﬁrst thank all reviewers for their thoughtful comments, and we wish everyone health during these hard times.",1 [R1]: 1. We acknowledge the simplicity in our linear demand and reference price update models. We made these modelling 2 decisions due to two reasons: (i) We intended to focus on the convergence of prices set by agents (who run mirror descent) when,Reinforcement Learning
"We thank the reviewers for their helpful suggestions, and will do our best to incorporate them into our paper. Overall,","1 we want to emphasize that the goal of SPECTRL is to make it easier to apply RL to tasks with complex objectives. In 2 particular, SPECTRL enables the user program what the agent needs to do at a high level; then, SPECTRL automatically",Reinforcement Learning
We would like to thank the reviewers for their thoughtful comments. Our paper makes the empirical point that state,1 of the art deep learning techniques don’t work in collaborative settings and we need human data to ﬁx this. It also 2 introduces the Overcooked environment as one in which coordination is key to achieve high reward. We are glad that,Deep Learning
"We thank all reviewers for detailed and valuable comments, and will revise the paper accordingly as described below.","1 Minor changes and typos. We thank all reviewers for pointing those out, and will do corrections in the revision. 2 R1 & R2: Discussions of deterministic MDPs in theoretical results. Although our theoretical results are derived in",Computer Vision
Thanks all the reviewers for the comments and suggestions!,"1 To Reviewer #1 2 • About 2-head attention Compared with the attention alignments in machine translation, the attention in TTS",Natural Language Processing
We thank all reviewers for their constructive and helpful comments.,1 Reviewer 1: We will be sure to provide a more accurate and nuanced discussion of the downsides of our auxiliary 2 bits requirements in a revision. The particular example we had in mind for the sentence on video was the case of,Computer Vision
We thank all the reviewers for their feedback. All reviewers are concerned whether we substantially outperform QMIX.,"1 Since StarCraft II experiments take a long time, we could not include all the results in the submission. However, we have 2 now obtained results for most of the SMAC maps [The StarCraft Multi-Agent Challenge, Samvelyan et al 2019], which",Reinforcement Learning
We thank the reviewers for their time and detailed reviews. We are happy to integrate their comments in our revision.,"1 R4 How is background knowledge about the intervention assignment incorporated into the likelihood function? 2 In Sections 3.1 & 3.2, the only information about interventions that we make use of is the data itself and the set of",Computer Vision
Thank you to the reviewers for the constructive and positive comments. Many comments had to do with positioning,"1 relative to existing work, which we will clarify in a revision. The comments can be broken into two groups: point 2 estimation methods and Bayesian methods.",Computer Vision
"We would like to thank all the reviewers for their constructive feedback. In the following, we respond (R) to individual","1 concerns (C) summarized in italic. Citations refer to references in the paper. 2 Reviewer 1. C: “...how does the term γT change as we increase number of actions K, and number of agents N?” R:",Reinforcement Learning
"We thank our reviewers for their insightful comments, and address their remarks below.","1 R1: Why SimCLR Episodes help supervision collapse? For example, in the ImageNet training set, all airplanes are 2 a single category. Therefore, for ProtoNets, the loss is minimized if all aircraft have identical features, which makes it",Computer Vision
Table 1: Extended “Table 2” in submitted paper. Segmentation results on BSD500 dataset.,Methods NCut NCut-DF DeepNCut,Computer Vision
We thank the reviewers for their helpful feedback. The reviews emphasized the signiﬁcance of our results for the,"1 analysis of ﬁnite-width neural networks (R1, R3) and the strength of our technical contributions (R1, R2). One primary 2 concern was that our results are only asymptotic. We address this concern and other questions below.",Deep Learning
We thank the reviewers for their detailed comments and their useful suggestions. We are excited that R1 and R4 ﬁnd,"1 our work interesting, timely and novel, and that our results demonstrate the fundamental limitations of Transformer 2 Language Models (TLMs) reasoning abilities. We thank R2 and R3 for acknowledging that our experiments show",Deep Learning
Reviewer 1 “What do...regret expressions represent? Why...max?” The regret expressions represent how suboptimal,"1 agents are in each of the games (i.e. how much assumptions 1,4 in each of the games are violated). They are aggregated 2 with a max since we would like to allow an ϵ-BNE in both G and G′. Aggregating, for example, with a sum would mean",Reinforcement Learning
All reviewers. Thank you for the constructive comments and suggestions. Our work (COOT) aims to exploit long-range,"1 temporal context and leverage hierarchy of semantics to learn joint video-text embeddings. COOT consists of three new 2 components: an Attention-aware Feature aggregation module (AF), a Contextual Transformer (CoT) and Cross-Modal",Deep Learning
We thank the reviewers for their thoughtful comments. We will address their comments in the revised version of the,"1 paper. We believe our contributions will be interesting to the ML community for several reasons: 2 • General, automatic methods to reduce memory consumption for large deep learning models are critical. To",Deep Learning
